<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>PECAN Poster Draft</title>
  <style>
    :root {
      --primary: #6d28d9;
      --secondary: #a855f7;
      --text: #1f2937;
      --muted: #6b7280;
      --bg: #ffffff;
      --border: #e5e7eb;
      --panel: #f5f3ff;
    }

    @page {
      size: 48in 36in;
      margin: 0;
    }

    html, body {
      margin: 0;
      padding: 0;
      background: var(--bg);
      color: var(--text);
      font-family: "Inter", Arial, sans-serif;
    }

    .poster {
      width: 48in;
      height: 36in;
      box-sizing: border-box;
      padding: 0.75in;
    }

    @media screen {
      body {
        display: flex;
        justify-content: center;
      }
      .poster {
        zoom: 0.25;
      }
    }

    @media print {
      html, body {
        width: 48in;
        height: 36in;
        overflow: hidden;
      }
      .poster {
        zoom: 1;
      }
    }

    .draft-banner {
      text-align: center;
      font-size: 2.5rem;
      letter-spacing: 0.5rem;
      text-transform: uppercase;
      color: var(--secondary);
      border: 4px dashed var(--secondary);
      padding: 0.5rem 0;
      margin-bottom: 1.5rem;
    }

    .title {
      text-align: center;
      margin-bottom: 1.25rem;
    }

    .title h1 {
      font-size: 4.2rem;
      margin: 0 0 0.5rem 0;
    }

    .title h2 {
      font-size: 2rem;
      font-weight: 500;
      margin: 0 0 0.75rem 0;
      color: var(--muted);
    }

    .meta {
      font-size: 1.3rem;
      color: var(--muted);
    }

    .grid {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 1.25rem;
    }

    .section {
      border: 2px solid var(--secondary);
      border-radius: 18px;
      padding: 1rem 1.25rem;
      background: var(--panel);
    }

    .section h3 {
      margin: 0 0 0.75rem 0;
      font-size: 2rem;
      color: var(--primary);
    }

    .section p,
    .section li {
      font-size: 1.35rem;
      line-height: 1.65;
      margin: 0 0 0.9rem 0;
    }

    .section.big-text p,
    .section.big-text li {
      font-size: 1.55rem;
      line-height: 1.75;
    }

    .section ul {
      margin: 0;
      padding-left: 1.2rem;
    }

    .metrics {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 0.75rem;
      margin-top: 0.75rem;
    }

    .metric {
      border: 2px solid var(--primary);
      border-radius: 12px;
      padding: 0.75rem;
      text-align: center;
      background: #ffffff;
    }

    .metric .value {
      font-size: 2.6rem;
      font-weight: 700;
      color: var(--primary);
    }

    .metric .label {
      font-size: 1.2rem;
      color: var(--muted);
    }

    .footer {
      margin-top: 1.5rem;
      display: grid;
      grid-template-columns: 2fr 1fr;
      gap: 1rem;
    }

    .placeholder {
      border: 2px dashed var(--border);
      border-radius: 12px;
      padding: 1rem;
      text-align: center;
      color: var(--muted);
      font-size: 1.1rem;
    }
  </style>
</head>
<body>
  <div class="poster">
    <div class="draft-banner">Draft</div>

    <header class="title">
      <h1>PECAN: Programming Encoder Classification Analysis Network</h1>
      <h2>Lightweight Transformer Encoders for Programming Language Identification</h2>
      <div class="meta">
        Dr. James Ghawaly · Ibrahim Alam · Jackson Descant<br>
        AISX Lab · Louisiana State University
      </div>
      <div class="meta">Stanford Research Conference 2026</div>
      <div style="margin-top: 0.75rem;">
        <img src="lsu-logo-1-2.png" alt="Louisiana State University logo" style="height: 90px;">
      </div>
    </header>

    <section class="grid">
      <div class="section">
        <h3>Abstract</h3>
        <p>
          PECAN (Programming Encoder Classification Analysis Network) is a research project focused on advancing lightweight, accurate programming language identification using encoder-only neural models. The goal of this research is to design, train, and rigorously evaluate efficient transformer-based encoders that can classify programming languages using raw code snippets, while maintaining strong generalization across diverse and modern codebases. Current language identification tools such as GuessLang and GitHub Linguist rely on heuristic-based methods or limited model architectures, which often struggle with ambiguous snippets, mixed-language repositories, and large-scale datasets. This project addresses these limitations by developing a unified experimental framework that evaluates encoder-only deep learning models across a broad and diverse corpus of programming languages with respect to accuracy, efficiency, and robustness. The research leverages an existing large-scale dataset of over 42 million code samples spanning more than 300 programming languages, alongside established benchmarks such as GuessLang. Training is conducted using PyTorch and Hugging Face Transformers, with distributed multi-GPU execution to ensure scalability. A comprehensive evaluation pipeline is implemented to compare performance, efficiency, and robustness across multiple model families, including pre-trained encoders and custom-trained architectures. The outcomes include (1) a systematic benchmark for lightweight programming language identification models, (2) insights into accuracy–efficiency tradeoffs for real-world deployment, and (3) research artifacts suitable for open-source release and potential publication. This work contributes to broader areas of software engineering, code analysis, and AI-assisted development tools.
        </p>
      </div>

      <div class="section big-text">
        <h3>Motivation</h3>
        <ul>
          <li>Existing systems struggle with ambiguous snippets and mixed-language repositories.</li>
          <li>Large-scale codebases demand scalable, efficient classifiers.</li>
          <li>Lightweight models enable production deployment without sacrificing accuracy.</li>
        </ul>
        <div class="metrics">
          <div class="metric">
            <div class="value">42M+</div>
            <div class="label">Code Samples</div>
          </div>
          <div class="metric">
            <div class="value">319</div>
            <div class="label">Languages</div>
          </div>
          <div class="metric">
            <div class="value">99.5%</div>
            <div class="label">Accuracy</div>
          </div>
        </div>
      </div>

      <div class="section big-text">
        <h3>Approach</h3>
        <ul>
          <li>Train encoder-only transformers on raw code snippets.</li>
          <li>Benchmark against GuessLang and GitHub Linguist baselines.</li>
          <li>Evaluate accuracy, efficiency, and robustness across model families and baselines.</li>
          <li>Run GuessLang in Docker; run Linguist, highlight.js, and GPT OSS inside the unified pipeline.</li>
          <li>Scale training with distributed multi-GPU infrastructure.</li>
        </ul>
        <p><strong>Stack:</strong> PyTorch, Hugging Face Transformers, W&amp;B, CUDA.</p>
      </div>

      <div class="section">
        <h3>Dataset</h3>
        <p>
          We leverage GuessLang and a larger custom dataset with 42 million+ code samples spanning
          319 languages to capture syntax variability and real-world repository diversity.
        </p>
        <div style="margin-top: 0.75rem;">
          <img src="pecan-language-distribution.svg" alt="Top language distribution from Pecan512 full dataset" style="width: 100%; border-radius: 12px; border: 2px solid #e2e8f0;">
          <p style="font-size: 1rem; color: #64748b; margin-top: 0.5rem;">
            Source: Pecan512 full dataset distribution (provided counts).
          </p>
        </div>
      </div>

      <div class="section big-text">
        <h3>Evaluation Pipeline</h3>
        <p>
          Evaluation routes depend on the model family. Fine-tuned encoder models are evaluated directly
          in the unified pipeline. GuessLang runs inside its Docker container, while GitHub Linguist is
          executed in the same pipeline (no Docker). We also evaluate with highlight.js and GPT OSS
          baselines for broader comparison.
        </p>
        <ul>
          <li><strong>Fine-tuned encoders:</strong> Standard pipeline evaluation (accuracy/efficiency/robustness)</li>
          <li><strong>GuessLang:</strong> Inference via Dockerized runtime</li>
          <li><strong>GitHub Linguist:</strong> Pipeline integration without Docker</li>
          <li><strong>highlight.js / GPT OSS:</strong> Additional baseline checks</li>
        </ul>
        <svg viewBox="0 0 1100 300" width="100%" height="360" role="img" aria-label="Evaluation pipeline diagram" style="margin-top: 1rem;">
          <rect x="10" y="70" width="200" height="120" rx="18" fill="#eef2ff" stroke="#2563eb" stroke-width="4"></rect>
          <text x="110" y="125" text-anchor="middle" font-size="30" fill="#0f172a">Data</text>
          <text x="110" y="158" text-anchor="middle" font-size="24" fill="#475569">42M+ samples</text>

          <rect x="240" y="70" width="200" height="120" rx="18" fill="#fdf2ff" stroke="#7c3aed" stroke-width="4"></rect>
          <text x="340" y="125" text-anchor="middle" font-size="28" fill="#0f172a">Encoders</text>
          <text x="340" y="158" text-anchor="middle" font-size="24" fill="#475569">Train &amp; fine-tune</text>

          <rect x="470" y="70" width="200" height="120" rx="18" fill="#ecfeff" stroke="#0891b2" stroke-width="4"></rect>
          <text x="570" y="125" text-anchor="middle" font-size="28" fill="#0f172a">Inference</text>
          <text x="570" y="158" text-anchor="middle" font-size="24" fill="#475569">Language ID</text>

          <rect x="700" y="70" width="200" height="120" rx="18" fill="#f0fdf4" stroke="#16a34a" stroke-width="4"></rect>
          <text x="800" y="125" text-anchor="middle" font-size="28" fill="#0f172a">Metrics</text>
          <text x="800" y="158" text-anchor="middle" font-size="24" fill="#475569">Accuracy · Efficiency</text>

          <rect x="930" y="70" width="160" height="120" rx="18" fill="#fff7ed" stroke="#ea580c" stroke-width="4"></rect>
          <text x="1010" y="125" text-anchor="middle" font-size="28" fill="#0f172a">Report</text>
          <text x="1010" y="158" text-anchor="middle" font-size="24" fill="#475569">Benchmarks</text>

          <line x1="210" y1="130" x2="230" y2="130" stroke="#0f172a" stroke-width="6" marker-end="url(#arrow)"></line>
          <line x1="440" y1="130" x2="460" y2="130" stroke="#0f172a" stroke-width="6" marker-end="url(#arrow)"></line>
          <line x1="670" y1="130" x2="690" y2="130" stroke="#0f172a" stroke-width="6" marker-end="url(#arrow)"></line>
          <line x1="900" y1="130" x2="920" y2="130" stroke="#0f172a" stroke-width="6" marker-end="url(#arrow)"></line>

          <defs>
            <marker id="arrow" markerWidth="8" markerHeight="8" refX="5" refY="3" orient="auto">
              <path d="M0,0 L6,3 L0,6 Z" fill="#0f172a"></path>
            </marker>
          </defs>
        </svg>
      </div>

      <div class="section">
        <h3>Results & Contributions</h3>
        <ul>
          <li>Established a systematic benchmark for lightweight language ID models.</li>
          <li>Quantified accuracy-efficiency tradeoffs for deployment.</li>
          <li>Produced research artifacts for open-source release and publication.</li>
        </ul>
        <div style="margin-top: 0.75rem;">
          <img src="W&BChartCodebertSweep.png" alt="CodeBERT fine-tuning sweep accuracy" style="width: 100%; border-radius: 12px; border: 2px solid #e2e8f0;">
          <p style="font-size: 1rem; color: #64748b; margin-top: 0.5rem;">
            CodeBERT fine-tuning sweep: eval accuracy over training steps.
          </p>
        </div>
      </div>
    </section>

    <section class="footer">
      <div class="section">
        <h3>Impact & Applications</h3>
        <p>
          PECAN enables stronger language detection for IDE tooling, repository analytics, and AI-driven
          software analysis. The lightweight architecture supports deployment in real-world systems
          where latency and compute budgets are constrained.
        </p>
        <ul>
          <li><strong>IDE/Editor tooling:</strong> Faster, more accurate language ID for mixed files and snippets.</li>
          <li><strong>Repository intelligence:</strong> Better language composition analysis for large codebases.</li>
          <li><strong>Security & compliance:</strong> Improved language-aware static analysis pipelines.</li>
          <li><strong>AI-assisted dev tools:</strong> More reliable code search, tagging, and dataset curation.</li>
        </ul>
      </div>

      <div class="section">
        <h3>Contact</h3>
        <p><strong>Email:</strong> ialam2@lsu.edu</p>
        <p><strong>Website:</strong> https://ialam04.github.io</p>
        <div class="placeholder">Placeholder: QR code to project page.</div>
      </div>
    </section>
  </div>
</body>
</html>
